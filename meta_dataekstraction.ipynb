{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import json\n",
    "import glob\n",
    "from numpyencoder import NumpyEncoder\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"Dataset\"\n",
    "METADATA= glob.glob(f\"{PATH}/**/**.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_meta_data(file_name,dict_file):\n",
    "    with open(f'{file_name}.json', 'w') as fp:\n",
    "        json.dump(dict_file, fp,  indent=4,cls=NumpyEncoder)\n",
    "\n",
    "def read_meta_data (path):\n",
    "    with open(path, 'r') as j:\n",
    "        contents = json.loads(j.read())\n",
    "        return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "buff = glob.glob(f\"{PATH}/T_316000_233500_NE_T_316000_233500_SW/**.txt\")\n",
    "data = np.array([i.split(\"/\") for i in buff if \"building\" in i or \"buidling\" in i])\n",
    "new= data[:,-1].copy()\n",
    "new = [i.split(\"_\") for i in new]\n",
    "for i,_ in enumerate(new):\n",
    "    if len(new[i])==2:\n",
    "        new[i][1] = new[i][1].split(\".\")\n",
    "        new[i][1][0]= new[i][1][0].zfill(3)\n",
    "        new[i][1]= \".\".join(new[i][1])\n",
    "    else:\n",
    "        new[i][1]=new[i][1].zfill(3)\n",
    "    new[i]= \"_\".join(new[i])\n",
    "index = np.where(data[:,-1]!=new)[0]\n",
    "if index.size != 0:\n",
    "    old_data= data[:,-1]\n",
    "    METADATA_buff = read_meta_data(f'{PATH}/T_316000_233500_NE_T_316000_233500_SW/meta_data.json')\n",
    "    OLD_METADATA_buff = METADATA_buff.copy()\n",
    "    for i in index:\n",
    "        try:\n",
    "            data_edited= METADATA_buff.pop(old_data[i][:-4])\n",
    "        except:\n",
    "            continue\n",
    "        list_new_data=new[i].split(\"/\")\n",
    "        METADATA_buff[list_new_data[-1][:-4]]={\n",
    "                                                \"path\":f\"T_316000_233500_NE_T_316000_233500_SW/{new[i]}\",\n",
    "                                                \"jumlah_point\":data_edited[\"jumlah_point\"]\n",
    "                                                }\n",
    "\n",
    "    print(index)\n",
    "    save_meta_data(f'{PATH}/T_316000_233500_NE_T_316000_233500_SW/meta_data',METADATA_buff)\n",
    "    for idx in index:\n",
    "        os.rename(f\"{PATH}/T_316000_233500_NE_T_316000_233500_SW/{old_data[idx]}\",f\"{PATH}/T_316000_233500_NE_T_316000_233500_SW/{new[idx]}\")\n",
    "    #     # print()\n",
    "    #     # print(old_data)\n",
    "METADATA= glob.glob(f\"{PATH}/**/**.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 15.03it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_list_per_instace(str_name ,file_list,Area,dict_file):\n",
    "    result_dict = {}\n",
    "    id_ns = np.unique(np.array([b.split(\"_\")[1] for b in dict_file],dtype=\"int16\"))\n",
    "    zf = 3 if Area ==  \"T_316000_233500_NE_T_316000_233500_SW\" or Area==\"T_315500_234500_SE\" else 2\n",
    "    for idn in id_ns :\n",
    "        r = re.compile(f\"{str_name}_{str(idn).zfill(zf)}\")\n",
    "        result_dict[f\"{str_name}_{str(idn).zfill(zf)}\"] = list(filter(r.match, file_list)) \n",
    "    return result_dict\n",
    "\n",
    "for i,_ in tqdm.tqdm(enumerate(METADATA),total=len(METADATA)):\n",
    "    Area = METADATA[i].split(\"/\")[1]\n",
    "    md = read_meta_data(METADATA[i])\n",
    "    file_names = md.keys()\n",
    "    building,ground,undefined,vegetation=[],[],[],[]\n",
    "    label = set([i.split(\"_\")[0] for i in file_names])\n",
    "    for fn in file_names:\n",
    "        if 'building' in fn.lower() or \"buidling\" in fn.lower():\n",
    "            building.append(fn)\n",
    "        if 'ground' in fn.lower():\n",
    "            ground.append(fn)\n",
    "        if 'undefined' in fn.lower() or \"undifined\" in fn.lower() or \"undefined\" in fn.lower() or 'Undefined' in fn.lower():\n",
    "            undefined.append(fn)\n",
    "        if 'vegetation'in fn.lower():\n",
    "            vegetation.append(fn)\n",
    "    dict_area={\n",
    "        \"building\":get_list_per_instace(str_name = \"building\",file_list = building,dict_file=building,Area=Area),\n",
    "        \"vegetation\":vegetation,\n",
    "        \"ground\":ground,\n",
    "        \"undefined\":undefined\n",
    "        }\n",
    "    save_meta_data(f\"map_ins_{Area}\",dict_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data = read_meta_data(\"map_ins_T_315500_234500_NW.json\")\n",
    "meta_data= read_meta_data(\"Dataset/T_315500_234500_NW/meta_data.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vegetation_bush_01',\n",
       " 'vegetation_bush_02',\n",
       " 'vegetation_bush_03',\n",
       " 'vegetation_bush_04',\n",
       " 'vegetation_bush_05',\n",
       " 'vegetation_bush_06',\n",
       " 'vegetation_bush_07',\n",
       " 'vegetation_bush_08',\n",
       " 'vegetation_bush_09',\n",
       " 'vegetation_bush_10',\n",
       " 'vegetation_bush_11',\n",
       " 'vegetation_bush_12',\n",
       " 'vegetation_bush_13',\n",
       " 'vegetation_bush_14',\n",
       " 'vegetation_bush_15',\n",
       " 'vegetation_tree_01',\n",
       " 'vegetation_tree_02',\n",
       " 'vegetation_tree_03',\n",
       " 'vegetation_tree_04',\n",
       " 'vegetation_tree_05',\n",
       " 'vegetation_tree_06',\n",
       " 'vegetation_tree_07',\n",
       " 'vegetation_tree_08',\n",
       " 'vegetation_tree_09',\n",
       " 'vegetation_tree_10',\n",
       " 'vegetation_tree_11',\n",
       " 'vegetation_tree_12',\n",
       " 'vegetation_tree_13',\n",
       " 'vegetation_tree_14',\n",
       " 'vegetation_tree_15',\n",
       " 'vegetation_tree_16',\n",
       " 'vegetation_tree_17',\n",
       " 'vegetation_tree_18',\n",
       " 'vegetation_tree_19',\n",
       " 'vegetation_tree_20',\n",
       " 'vegetation_tree_21',\n",
       " 'vegetation_tree_22',\n",
       " 'vegetation_tree_23',\n",
       " 'vegetation_tree_24',\n",
       " 'vegetation_tree_25',\n",
       " 'vegetation_tree_26',\n",
       " 'vegetation_tree_27',\n",
       " 'vegetation_tree_28',\n",
       " 'vegetation_tree_29',\n",
       " 'vegetation_tree_30',\n",
       " 'vegetation_tree_31',\n",
       " 'vegetation_tree_32',\n",
       " 'vegetation_tree_33',\n",
       " 'vegetation_tree_34',\n",
       " 'vegetation_tree_35',\n",
       " 'vegetation_tree_36',\n",
       " 'vegetation_tree_37',\n",
       " 'vegetation_tree_38',\n",
       " 'vegetation_tree_39',\n",
       " 'vegetation_tree_40',\n",
       " 'vegetation_tree_41',\n",
       " 'vegetation_tree_42',\n",
       " 'vegetation_tree_43',\n",
       " 'vegetation_tree_44',\n",
       " 'vegetation_tree_45',\n",
       " 'vegetation_tree_46',\n",
       " 'vegetation_tree_47',\n",
       " 'vegetation_tree_48',\n",
       " 'vegetation_tree_49',\n",
       " 'vegetation_tree_50',\n",
       " 'vegetation_tree_51',\n",
       " 'vegetation_tree_52',\n",
       " 'vegetation_tree_53',\n",
       " 'vegetation_tree_54',\n",
       " 'vegetation_tree_55',\n",
       " 'vegetation_tree_56',\n",
       " 'vegetation_tree_57',\n",
       " 'vegetation_tree_58',\n",
       " 'vegetation_tree_59',\n",
       " 'vegetation_tree_60',\n",
       " 'vegetation_tree_61',\n",
       " 'vegetation_tree_62',\n",
       " 'vegetation_tree_63',\n",
       " 'vegetation_tree_64',\n",
       " 'vegetation_tree_65',\n",
       " 'vegetation_tree_66',\n",
       " 'vegetation_tree_67',\n",
       " 'vegetation_tree_68']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_data[\"vegetation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maping_meta_data(class_name,map_data,meta_data):\n",
    "    inst_id = {}\n",
    "    try:\n",
    "        for count,key in enumerate(map_data[class_name]):\n",
    "            try:\n",
    "                k_split = key.split(\"_\")\n",
    "                if len(k_split)==3:\n",
    "                    _,sub_class,key_id = k_split\n",
    "                else :\n",
    "                    sub_class,key_id[:-4] = k_split\n",
    "            except:\n",
    "                sub_class,key_id=key,0\n",
    "                \n",
    "            inst_id[str(count).zfill(3)]={\n",
    "                \"total_point\": meta_data[key][\"jumlah_point\"],\n",
    "                \"path\": meta_data[key][\"path\"],\n",
    "                \"sub_class\": sub_class,\n",
    "                \"id\": str(int(key_id)-1).zfill(3)\n",
    "                }\n",
    "    except Exception as e:\n",
    "        print(class_name)\n",
    "        print(meta_data[class_name])\n",
    "        inst_id[\"000\"]={\n",
    "            \"total_point\": meta_data[class_name][\"jumlah_point\"],\n",
    "            \"path\": meta_data[class_name][\"path\"],\n",
    "            \"sub_class\": \"000\",\n",
    "            \"id\": \"000\"\n",
    "            }\n",
    "    return inst_id\n",
    "    \n",
    "def map_to_inst(map_data_json,meta_data_json):\n",
    "    map_data = read_meta_data(map_data_json)\n",
    "    meta_data= read_meta_data(meta_data_json)\n",
    "    for k in map_data.keys():\n",
    "        if k == \"building\":\n",
    "            inst_id_building = {}\n",
    "            list_build_id= list(map_data[k].keys())\n",
    "            for id_b in list_build_id:\n",
    "                id_ins = str(int(id_b.split(\"_\")[-1])-1).zfill(3)\n",
    "                total_point = sum([meta_data[i][\"jumlah_point\"] for i in map_data[list(map_data.keys())[0]][id_b]])\n",
    "                list_all_txt = [meta_data[i][\"path\"] for i in map_data[list(map_data.keys())[0]][id_b]]\n",
    "                inst_id_building[id_ins]={\n",
    "                    \"total_point\":total_point,\n",
    "                    \"path\":list_all_txt\n",
    "                    }\n",
    "        elif k==\"vegetation\" :\n",
    "            inst_id_vegetation = maping_meta_data(\"vegetation\",map_data,meta_data)\n",
    "        elif k==\"ground\" :\n",
    "            inst_id_ground = maping_meta_data(\"ground\",map_data,meta_data)\n",
    "        else :\n",
    "            inst_id_undefined = maping_meta_data(\"undefined\",map_data,meta_data)\n",
    "    return [inst_id_building,inst_id_vegetation,inst_id_ground,inst_id_undefined]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,_ in enumerate(METADATA):\n",
    "    area=METADATA[i].split(\"/\")[1]\n",
    "    ins = map_to_inst(f\"map_ins_{area}.json\",METADATA[i])\n",
    "    save_meta_data(f\"map_ins_{area}\",{\"building\":ins[0],\"vegetation\":ins[1],\"ground\":ins[2],'undefined':ins[3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [37:03<00:00, 171.02s/it]\n"
     ]
    }
   ],
   "source": [
    "MAPTOINST_META_LIST= glob.glob(\"map_**\")\n",
    "def get_combining_building_data(map_data_json = MAPTOINST_META_LIST) :   \n",
    "    for i in tqdm.tqdm(range(len(map_data_json))):\n",
    "        map_data = read_meta_data(map_data_json[i])[\"building\"]\n",
    "        buff_folder = f\"all_data_building/{map_data_json[i][8:-5]}\"\n",
    "        os.makedirs(buff_folder,exist_ok=True)\n",
    "        map_data_id= list(map_data.keys())\n",
    "        for mdi in map_data_id:\n",
    "            list_data_txt = map_data[mdi][\"path\"]\n",
    "            # Start from init = 0 and append until last\n",
    "            all_data = np.loadtxt(f\"Dataset/{list_data_txt[0]}\")[:,:6]\n",
    "            try:\n",
    "                for idx in range(1,len(list_data_txt)):\n",
    "                    buff = np.loadtxt(f\"Dataset/{list_data_txt[idx]}\")[:,:6]\n",
    "                    all_data = np.append(all_data,buff,axis=0)\n",
    "            except :\n",
    "                pass\n",
    "            save_npy_loc = f\"{buff_folder}/building_{mdi}.npy\"\n",
    "            map_data[mdi][\"path_all_data\"] = save_npy_loc\n",
    "            np.save(f\"{buff_folder}/building_{mdi}.npy\",all_data,allow_pickle=True)\n",
    "        old_map = read_meta_data(map_data_json[i])\n",
    "        old_map[\"building\"]= map_data\n",
    "        save_meta_data(f\"{map_data_json[i][8:-5]}\",old_map)\n",
    "get_combining_building_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_build    = glob.glob(\"T_**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id_ in range(len(map_build)):\n",
    "#     building_metadata = read_meta_data(map_build[id_])[\"building\"]\n",
    "#     map_ins = read_meta_data(f\"map_ins_{map_build[id_]}\")\n",
    "#     map_ins.pop(\"building\")\n",
    "#     map_ins[\"building\"]=building_metadata\n",
    "#     save_meta_data(map_build[id_][:-5],map_ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc647e2225573627561fd5069e9d88ac514047f3a8797e32712e149d4deab2d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
